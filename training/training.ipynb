{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of CSV file paths\n",
    "file_paths = [\n",
    "    'Collected Dataset/fist.csv',\n",
    "    'Collected Dataset/hand_open.csv',\n",
    "    'Collected Dataset/index_middle_thumb.csv',\n",
    "    'Collected Dataset/index_middle.csv',\n",
    "    'Collected Dataset/index_thumb.csv',\n",
    "    'Collected Dataset/index.csv',\n",
    "    'Collected Dataset/pinch.csv',\n",
    "    'Collected Dataset/peace.csv',\n",
    "    'Collected Dataset/thumbs_pinky.csv',\n",
    "    'Collected Dataset/thumbs_down.csv',\n",
    "    'Collected Dataset/thumbs_up.csv'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data = [pd.read_csv(file) for file in file_paths]\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "data = pd.concat(csv_data, ignore_index=True)\n",
    "\n",
    "# Shuffle the DataFrame\n",
    "data = data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramez\\AppData\\Local\\Temp\\ipykernel_6132\\1048893778.py:8: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  y.replace(string_to_numeric, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(88549, 63)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "string_to_numeric = {'index': 0, 'index_middle': 1, 'index_thumb': 2, 'index_middle_thumb' : 3, 'peace': 4, 'hand_open' : 5, 'fist': 6, 'pinch' : 7, 'thumbs_up' : 8, 'thumbs_down': 9 , 'thumbs_pinky' : 10}\n",
    "\n",
    "# string_to_numeric = {'index': 0, 'index_middle': 1, 'index_thumb': 2, 'index_middle_thumb' : 3, 'fist': 4, 'hand_open' : 5}\n",
    "\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]\n",
    "\n",
    "y.replace(string_to_numeric, inplace=True)\n",
    "\n",
    "X.sample(1)\n",
    "\n",
    "# remove column names\n",
    "X = X.values\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (61984, 63)\n",
      "Testing data shape: (13282, 63)\n",
      "Validation data shape: (13283, 63)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test_val, y_train, y_test_val = train_test_split(X, y, test_size=0.3, random_state=12)\n",
    "\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test_val, y_test_val, test_size=0.5, random_state=12)\n",
    "\n",
    "print(\"Training data shape:\", X_train.shape)\n",
    "print(\"Testing data shape:\", X_test.shape)\n",
    "print(\"Validation data shape:\", X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape after PCA: (61984, 20)\n"
     ]
    }
   ],
   "source": [
    "# apply pca\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pca = PCA(n_components=0.99)\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "X_val_pca = pca.transform(X_val)\n",
    "\n",
    "print(\"Training data shape after PCA:\", X_train_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save pca model\n",
    "import pickle\n",
    "\n",
    "with open('../utils/pca.pkl', 'wb') as f:\n",
    "    pickle.dump(pca, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Hyperparameter tuned models\n",
    "\n",
    "my_models = {\n",
    "#     (\"KNN\", KNeighborsClassifier(algorithm = 'auto', n_neighbors = 3)),\n",
    "    (\"Decision Tree\", DecisionTreeClassifier(criterion = 'entropy', max_depth = 30, min_samples_split = 2, splitter = 'best')),\n",
    "    # (\"Random Forest\", RandomForestClassifier(criterion = 'entropy', max_depth = 20, n_estimators = 50)),\n",
    "    # (\"Logistic Regression\", LogisticRegression(C = 10, solver = 'newton-cg')),\n",
    "    # (\"XGBoost\", XGBClassifier(learning_rate=0.2, max_depth=6, n_estimators= 50))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Decision Tree\n",
      "Training Accuracy: 1.0\n",
      "Validation Accuracy: 0.9980426108559813\n",
      "Testing Accuracy: 0.9990212317422075\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, model in my_models:\n",
    "    print(\"Training\", name)\n",
    "    model.fit(X_train_pca, y_train)\n",
    "    print(\"Training Accuracy:\", model.score(X_train_pca, y_train))\n",
    "    print(\"Validation Accuracy:\", model.score(X_val_pca, y_val))\n",
    "    print(\"Testing Accuracy:\", model.score(X_test_pca, y_test))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8  1  4  9  7  3  0  2 10  5  6]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "num_states = len(y.unique())\n",
    "\n",
    "print(y.unique())\n",
    "\n",
    "tf_model = models.Sequential([\n",
    "    layers.Input(shape=(X_train_pca.shape[1],)), \n",
    "    tf.keras.layers.Dense(24, activation= 'relu'), \n",
    "    # tf.keras.layers.Dense(64, activation= 'relu'), \n",
    "    # tf.keras.layers.Dense(128, activation= 'relu'), \n",
    "    tf.keras.layers.Dense(num_states, activation= 'softmax')\n",
    "])\n",
    "                                \n",
    "# Compile the model\n",
    "tf_model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "\n",
    "# Train the model with early stopping\n",
    "history = tf_model.fit(\n",
    "    # X_train, y_train,\n",
    "    X_train_pca, y_train,\n",
    "    epochs=10,\n",
    "    # validation_data=(X_val, y_val),\n",
    "    validation_data=(X_val_pca, y_val),\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw confusion matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import time \n",
    "start = time.time()\n",
    "y_pred = tf_model(X_test_pca)\n",
    "end = time.time()\n",
    "print(\"Time taken for prediction:\", end-start)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "print(\"\\nAccuracy:\", np.trace(cm) / np.sum(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Decision Tree\n",
      "Time taken for prediction: 0.0065805912017822266\n",
      "[[1319    2    0    1    2    0    1    0    0    0    0]\n",
      " [   1 1107    0    0    0    0    1    0    0    0    0]\n",
      " [   0    0 1456    0    0    0    0    0    0    0    0]\n",
      " [   2    0    0 1365    0    0    0    0    0    0    0]\n",
      " [   0    2    0    0 1452    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0 1247    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0  974    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0 1214    0    0    0]\n",
      " [   0    0    0    0    0    1    0    0  848    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0 1042    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0 1245]]\n",
      "\n",
      "Testing Accuracy: 0.9990212317422075\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import time \n",
    "\n",
    "for name, model in my_models:\n",
    "    print(\"Model:\", name)\n",
    "    start = time.time()\n",
    "    y_pred = model.predict(X_test_pca)\n",
    "    end = time.time()\n",
    "    print(\"Time taken for prediction:\", end-start)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(cm)\n",
    "    print()\n",
    "    print(\"Testing Accuracy:\", model.score(X_test_pca, y_test))\n",
    "    print()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in my_models:\n",
    "    # if name == \"Random Forest\":\n",
    "    if name == \"Decision Tree\":\n",
    "        import pickle\n",
    "        with open('../models/d_tree.pkl', 'wb') as f:\n",
    "            pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "tf_model.save('../model/tfv4.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Virtual Mouse - Hand Tracking",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
