{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Normalized Dataset (Unzip it first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = [\n",
    "    'collected dataset/fist_1.csv',\n",
    "    'collected dataset/fist_2.csv',\n",
    "    \n",
    "    'collected dataset/hand_open_1.csv',\n",
    "    \n",
    "    'collected dataset/index_1.csv',\n",
    "    'collected dataset/index_2.csv',\n",
    "    'collected dataset/index_3.csv',\n",
    "    'collected dataset/index_4.csv',\n",
    "    \n",
    "    \n",
    "    'collected dataset/index_middle_1.csv',\n",
    "    'collected dataset/index_middle_2.csv',\n",
    "    'collected dataset/index_middle_3.csv',\n",
    "    'collected dataset/index_middle_4.csv',\n",
    "    \n",
    "    'collected dataset/index_middle_thumb_1.csv',\n",
    "    \n",
    "    'collected dataset/index_thumb_1.csv',\n",
    "\n",
    "    'collected dataset/peace_1.csv',\n",
    "    \n",
    "    'collected dataset/pinch_1.csv',\n",
    "    \n",
    "    'collected dataset/thumbs_down_1.csv',\n",
    "    \n",
    "    'collected dataset/thumbs_pinky_1.csv',\n",
    "    'collected dataset/thumbs_pinky_2.csv',\n",
    "    'collected dataset/thumbs_pinky_3.csv',\n",
    "    \n",
    "    'collected dataset/thumbs_up_1.csv',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data = [pd.read_csv(file) for file in file_paths]\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "data = pd.concat(csv_data, ignore_index=True)\n",
    "\n",
    "# Shuffle the DataFrame\n",
    "data = data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove missing values\n",
    "df = data.dropna()\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace string labels with numbers & remove column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_to_numeric = {'index': 0, 'index_middle': 1, 'index_thumb': 2, 'index_middle_thumb' : 3, 'peace': 4, 'hand_open' : 5, 'fist': 6, 'pinch' : 7, 'thumbs_up' : 8, 'thumbs_down': 9 , 'thumbs_pinky' : 10}\n",
    "\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "y.replace(string_to_numeric, inplace=True)\n",
    "\n",
    "X.sample(1)\n",
    "\n",
    "# remove column names\n",
    "X = X.values\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, test and validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test_val, y_train, y_test_val = train_test_split(X, y, test_size=0.3, random_state=12)\n",
    "\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test_val, y_test_val, test_size=0.5, random_state=12)\n",
    "\n",
    "print(\"Training data shape:\", X_train.shape)\n",
    "print(\"Testing data shape:\", X_test.shape)\n",
    "print(\"Validation data shape:\", X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=0.99)\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "X_val_pca = pca.transform(X_val)\n",
    "\n",
    "print(\"Training data shape after PCA:\", X_train_pca.shape)\n",
    "print(X_test_pca.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save PCA model\n",
    "import pickle\n",
    "\n",
    "with open('../utils/pca.pkl', 'wb') as f:\n",
    "    pickle.dump(pca, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing non-tensorflow models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Hyperparameter tuned models\n",
    "\n",
    "my_models = {\n",
    "    (\"KNN\", KNeighborsClassifier(algorithm = 'auto', n_neighbors = 3)),\n",
    "    (\"Decision Tree\", DecisionTreeClassifier(criterion = 'entropy', max_depth = 30, min_samples_split = 2, splitter = 'best')),\n",
    "    (\"Random Forest\", RandomForestClassifier(criterion = 'entropy', max_depth = 20, n_estimators = 50)),\n",
    "    (\"XGBoost\", XGBClassifier(learning_rate=0.2, max_depth=6, n_estimators= 50))\n",
    "    (\"MLP\", MLPClassifier(hidden_layer_sizes=(128,64), activation='relu', solver='adam', max_iter=1000, early_stopping=True, n_iter_no_change=3))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "for name, model in my_models:\n",
    "    print(\"Training\", name)\n",
    "    model.fit(X_train_pca, y_train)\n",
    "    print(\"Training Accuracy:\", model.score(X_train_pca, y_train))\n",
    "    print(\"Validation Accuracy:\", model.score(X_val_pca, y_val))\n",
    "    print(\"Testing Accuracy:\", model.score(X_test_pca, y_test))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "for name, model in my_models:\n",
    "    print(\"Model:\", name)\n",
    "    start = time.time()\n",
    "    y_pred = model.predict(X_test_pca)\n",
    "    end = time.time()\n",
    "    print(\"Time taken for prediction:\", end-start)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(cm)\n",
    "    print()\n",
    "    print(\"Testing Accuracy:\", model.score(X_test_pca, y_test))\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save chosen model from the above models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in my_models:\n",
    "    if name == \"MLP\":\n",
    "        import pickle\n",
    "        with open('../models/gesture_detector_mlp.pkl', 'wb') as f:\n",
    "            pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and testing Tensorflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "num_states = len(y.unique())\n",
    "\n",
    "print(y.unique())\n",
    "\n",
    "tf_model = models.Sequential([\n",
    "    layers.Input(shape=(X_train_pca.shape[1],)), \n",
    "    tf.keras.layers.Dense(64, activation= 'relu'), \n",
    "    tf.keras.layers.Dense(num_states, activation= 'softmax')\n",
    "])\n",
    "                                \n",
    "# Compile the model\n",
    "tf_model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "\n",
    "# Train the model with early stopping\n",
    "history = tf_model.fit(\n",
    "    X_train_pca, y_train,\n",
    "    epochs=50,\n",
    "    validation_data=(X_val_pca, y_val),\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw confusion matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import time \n",
    "start = time.time()\n",
    "y_pred = tf_model(X_test_pca)\n",
    "end = time.time()\n",
    "print(\"Time taken for prediction:\", end-start)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "print(\"\\nAccuracy:\", np.trace(cm) / np.sum(cm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Tensorflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save tensorflow model\n",
    "tf_model.save('../models/tf_model.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Virtual Mouse - Hand Tracking",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
