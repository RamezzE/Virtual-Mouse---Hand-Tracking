{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of CSV file paths\n",
    "file_paths = [\n",
    "    'Collected Dataset/fist.csv',\n",
    "    'Collected Dataset/hand_open.csv',\n",
    "    'Collected Dataset/index_middle_thumb.csv',\n",
    "    'Collected Dataset/index_middle.csv',\n",
    "    'Collected Dataset/index_thumb.csv',\n",
    "    'Collected Dataset/index.csv',\n",
    "    'Collected Dataset/pinch.csv',\n",
    "    'Collected Dataset/peace.csv',\n",
    "    'Collected Dataset/thumbs_pinky.csv',\n",
    "    'Collected Dataset/thumbs_down.csv',\n",
    "    'Collected Dataset/thumbs_up.csv'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data = [pd.read_csv(file) for file in file_paths]\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "data = pd.concat(csv_data, ignore_index=True)\n",
    "\n",
    "# Shuffle the DataFrame\n",
    "data = data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramez\\AppData\\Local\\Temp\\ipykernel_7856\\1048893778.py:8: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  y.replace(string_to_numeric, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(88549, 63)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "string_to_numeric = {'index': 0, 'index_middle': 1, 'index_thumb': 2, 'index_middle_thumb' : 3, 'peace': 4, 'hand_open' : 5, 'fist': 6, 'pinch' : 7, 'thumbs_up' : 8, 'thumbs_down': 9 , 'thumbs_pinky' : 10}\n",
    "\n",
    "# string_to_numeric = {'index': 0, 'index_middle': 1, 'index_thumb': 2, 'index_middle_thumb' : 3, 'fist': 4, 'hand_open' : 5}\n",
    "\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]\n",
    "\n",
    "y.replace(string_to_numeric, inplace=True)\n",
    "\n",
    "X.sample(1)\n",
    "\n",
    "# remove column names\n",
    "X = X.values\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (61984, 63)\n",
      "Testing data shape: (13282, 63)\n",
      "Validation data shape: (13283, 63)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test_val, y_train, y_test_val = train_test_split(X, y, test_size=0.3, random_state=12)\n",
    "\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test_val, y_test_val, test_size=0.5, random_state=12)\n",
    "\n",
    "print(\"Training data shape:\", X_train.shape)\n",
    "print(\"Testing data shape:\", X_test.shape)\n",
    "print(\"Validation data shape:\", X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape after PCA: (61984, 13)\n"
     ]
    }
   ],
   "source": [
    "# apply pca\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pca = PCA(n_components=0.95)\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "X_val_pca = pca.transform(X_val)\n",
    "\n",
    "print(\"Training data shape after PCA:\", X_train_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save pca model\n",
    "import pickle\n",
    "\n",
    "with open('../utils/pca.pkl', 'wb') as f:\n",
    "    pickle.dump(pca, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.neural_network import MLPClassifier\n",
    "# from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Hyperparameter tuned models\n",
    "\n",
    "my_models = {\n",
    "#     (\"KNN\", KNeighborsClassifier(algorithm = 'auto', n_neighbors = 3)),\n",
    "#     (\"Decision Tree\", DecisionTreeClassifier(criterion = 'entropy', max_depth = None)),\n",
    "    (\"Random Forest\", RandomForestClassifier(criterion = 'entropy', max_depth = 20, n_estimators = 200)),\n",
    "#     (\"Logistic Regression\", LogisticRegression(C = 10, solver = 'newton-cg')),\n",
    "#     (\"MLP\", MLPClassifier(activation = 'tanh', hidden_layer_sizes = (64, 128), solver = 'adam')),\n",
    "#     (\"SVM\", SVC(C=10, gamma='scale', kernel='poly')),\n",
    "    (\"XGBoost\", XGBClassifier(learning_rate=0.1, max_depth=6, n_estimators=200))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost\n",
      "Training Accuracy: 1.0\n",
      "Validation Accuracy: 0.9996988632086126\n",
      "Testing Accuracy: 0.9996988405360638\n",
      "\n",
      "Training Random Forest\n",
      "Training Accuracy: 1.0\n",
      "Validation Accuracy: 0.9997741474064594\n",
      "Testing Accuracy: 0.9997741304020479\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, model in my_models:\n",
    "    print(\"Training\", name)\n",
    "    model.fit(X_train_pca, y_train)\n",
    "    print(\"Training Accuracy:\", model.score(X_train_pca, y_train))\n",
    "    print(\"Validation Accuracy:\", model.score(X_val_pca, y_val))\n",
    "    print(\"Testing Accuracy:\", model.score(X_test_pca, y_test))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7  9  1  5  4  2  8  6 10  3  0]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "num_states = len(y.unique())\n",
    "\n",
    "print(y.unique())\n",
    "\n",
    "tf_model = models.Sequential([\n",
    "    # layers.Input(shape=(X.shape[1],)),  # Input layer specifying the input shape\n",
    "    layers.Input(shape=(X_train_pca.shape[1],)),  # Input layer specifying the input shape\n",
    "    tf.keras.layers.Dense(64, activation= 'relu'), \n",
    "    tf.keras.layers.Dense(128, activation= 'relu'), \n",
    "    tf.keras.layers.Dense(num_states, activation= 'softmax')\n",
    "])\n",
    "                                \n",
    "# Compile the model\n",
    "tf_model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1937/1937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8805 - loss: 0.4803 - val_accuracy: 0.9940 - val_loss: 0.0251\n",
      "Epoch 2/10\n",
      "\u001b[1m1937/1937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9941 - loss: 0.0229 - val_accuracy: 0.9954 - val_loss: 0.0150\n",
      "Epoch 3/10\n",
      "\u001b[1m1937/1937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9954 - loss: 0.0156 - val_accuracy: 0.9966 - val_loss: 0.0101\n",
      "Epoch 4/10\n",
      "\u001b[1m1937/1937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9965 - loss: 0.0107 - val_accuracy: 0.9978 - val_loss: 0.0067\n",
      "Epoch 5/10\n",
      "\u001b[1m1937/1937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9972 - loss: 0.0083 - val_accuracy: 0.9979 - val_loss: 0.0062\n",
      "Epoch 6/10\n",
      "\u001b[1m1937/1937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9975 - loss: 0.0077 - val_accuracy: 0.9988 - val_loss: 0.0038\n",
      "Epoch 7/10\n",
      "\u001b[1m1937/1937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.0048 - val_accuracy: 0.9980 - val_loss: 0.0061\n",
      "Epoch 8/10\n",
      "\u001b[1m1937/1937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9980 - loss: 0.0051 - val_accuracy: 0.9983 - val_loss: 0.0041\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "\n",
    "# Train the model with early stopping\n",
    "history = tf_model.fit(\n",
    "    # X_train, y_train,\n",
    "    X_train_pca, y_train,\n",
    "    epochs=10,\n",
    "    # validation_data=(X_val, y_val),\n",
    "    validation_data=(X_val_pca, y_val),\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for prediction: 0.029997587203979492\n",
      "[[1291    3    0    0    0    0    1    0    0    0    0]\n",
      " [   4 1045    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0 1449    2    0    0    0    0    0    0    0]\n",
      " [   0    0    8 1362    0    2    0    0    0    0    0]\n",
      " [   0    0    0    0 1461    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0 1210    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0  962    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0 1327    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0  827    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0 1047    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0 1281]]\n",
      "\n",
      "Accuracy: 0.9984942026803192\n"
     ]
    }
   ],
   "source": [
    "# draw confusion matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import time \n",
    "start = time.time()\n",
    "y_pred = tf_model(X_test_pca)\n",
    "end = time.time()\n",
    "print(\"Time taken for prediction:\", end-start)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "print(\"\\nAccuracy:\", np.trace(cm) / np.sum(cm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: XGBoost\n",
      "Time taken for prediction: 0.2619955539703369\n",
      "[[1295    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0 1049    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0 1449    1    0    0    0    0    1    0    0]\n",
      " [   0    0    2 1370    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0 1461    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0 1210    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0  962    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0 1327    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0  827    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0 1047    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0 1281]]\n",
      "\n",
      "Testing Accuracy: 0.9996988405360638\n",
      "\n",
      "Model: Random Forest\n",
      "Time taken for prediction: 0.6000027656555176\n",
      "[[1295    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0 1049    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0 1451    0    0    0    0    0    0    0    0]\n",
      " [   0    0    3 1369    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0 1461    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0 1210    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0  962    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0 1327    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0  827    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0 1047    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0 1281]]\n",
      "\n",
      "Testing Accuracy: 0.9997741304020479\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import time \n",
    "\n",
    "for name, model in my_models:\n",
    "    print(\"Model:\", name)\n",
    "    start = time.time()\n",
    "    y_pred = model.predict(X_test_pca)\n",
    "    end = time.time()\n",
    "    print(\"Time taken for prediction:\", end-start)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(cm)\n",
    "    print()\n",
    "    print(\"Testing Accuracy:\", model.score(X_test_pca, y_test))\n",
    "    print()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in my_models:\n",
    "    # if name == \"Random Forest\":\n",
    "    if name == \"XGBoost\":\n",
    "        import pickle\n",
    "        with open('../models/xgboost.pkl', 'wb') as f:\n",
    "            pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "tf_model.save('../model/tfv4.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Virtual Mouse - Hand Tracking",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
